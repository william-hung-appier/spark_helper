# Improve UX & get latest fields from corresponding tables

## Background/Context

- This new 2.0.0 version focusing on enhancing UX and can always fetch latest tables corresponding schema.
- Previous extension behavior will read with hard coded fields defined by the code instead of referencing the spark schema team fields which may cause fields always needs to be updated manually.
- Have use git submodule feature to pull the spark [schema](../schemas/) team repository under this project.
- UX improvement design:
  - FROM and SELECT clause support type to search experience with reasonable debouncing delay.
  - User should choose table name FIRST.
    - Supporting total 4 tables with reading corresponding [table schema](../schemas/spark/).
      - [imp_join_all2](../schemas/spark/imp_join_all2.yaml)
      - [creative_perf_event](../schemas/spark/creative_perf_event.yaml)
      - [creative_quality](../schemas/spark/creative_quality.yaml)
      - [creative_event](../schemas/spark/creative_event.yaml)
    - Tables still support UTC time transfer feature.
  - Able to type in the SELECT clause to find target corresponding fields in table INSTEAD OF old scrolling and select behavior

## AS-IS

1. We read the web page html to parse schema base on pre-defined [script](../src/js/fieldMappings.js) and fallback [schema](../src/js/defaultSchema.js) for imp_join_all2 table
2. Currently ONLY support 1 table: `imp_join_all2`
3. For normal flow, user will defined SELECT clause first then FROM clause
4. While user clicking add new field btn in SELECT clause field will pop out a very long field to let user scroll to choose
5. custom defined fields for imp_join_all2 [script](../src/js/fieldMappings.js) naming is too general since this is just for imp_join_all2 table
6. We default help user detect if field is `binary` type then will apply `BYTES2STR` UDF.
7. [Project document](../README.md) guideline is old ones
8. [LLM agent doc](../CLAUDE.md) is using 1.1.3 version

## TO-BE

1. We delete those hard coded or read from html feature and script and use the schema defined in the project directly.
2. We support 4 tables: `imp_join_all2`, `creative_perf_event`, `creative_quality`, and `creative_event`. All of them should all support UTC transfer time feature.
3. User should Choose table and the time in FROM clause first then the SELECT clause
4. While user clicking add new field btn should show out some kind of search bar allowing user to type and have a debouncing behavior for suggestion with user typed value. (pattern will use start_with the value is same and case non-sensitive)
5. should have a new folder/path structure for allowing defining custom defined fields for different tables
6. the default binary type detect and uses `BYTES2STR` should still keep it but we don't need to show up to user in the SELECT clause
7. should update project document
8. should update agent document
9. Update entry [script](../Makefile) with new command `update-spark-schema` to let user can always fetch/pull the latest schema which can read by this extension.
10. Generated Query output should be editable by user for manual adjustments
11. Add a Clear button to quickly reset the Generated Query output
12. Pressing Enter in autocomplete dropdown should select the first suggestion (same as click behavior)
